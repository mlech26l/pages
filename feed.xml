<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://mlech26l.github.io/pages/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mlech26l.github.io/pages/" rel="alternate" type="text/html" /><updated>2020-09-17T01:55:47-05:00</updated><id>https://mlech26l.github.io/pages/feed.xml</id><title type="html">Home</title><subtitle>Personal research blog and webpage</subtitle><entry><title type="html">The wormnet project</title><link href="https://mlech26l.github.io/pages/2020/09/14/wormnet1.html" rel="alternate" type="text/html" title="The wormnet project" /><published>2020-09-14T00:00:00-05:00</published><updated>2020-09-14T00:00:00-05:00</updated><id>https://mlech26l.github.io/pages/2020/09/14/wormnet1</id><content type="html" xml:base="https://mlech26l.github.io/pages/2020/09/14/wormnet1.html">&lt;p&gt;This is the first part in a series explaining our recent paper titled XXX.&lt;/p&gt;

&lt;p&gt;In progress.&lt;/p&gt;

&lt;h2 id=&quot;biological-vs-artificial-neural-networks&quot;&gt;Biological vs artificial neural networks&lt;/h2&gt;

&lt;p&gt;The term &lt;em&gt;neural&lt;/em&gt; implies the origin of neural networks lies in biological nervous systems. Indeed, artificial neural networks’ original purpose was to build intelligent algorithms inspired by how information processing happens in human and animal brains. 
However, modern neural networks for building powerful machine learning models look quite distinct compared to their biological counterparts.
There are two critical differences between artificial and biological neural networks: the computational model and the architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/wormnet/t.png&quot; alt=&quot;award&quot; title=&quot;Left: Resnet architecture (He et al. 2016), Right: Subset of the C. elegans connectome (Copyright Emmons Lab/wormwiring.org)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Biological neurons are cells whose cell-wall have an electrical charge depending on the concentration of certain ions inside vs. outside the cell. 
The number of ions inside the cell can be changed by mechanisms of the cell itself when the cell’s electrical charge exceeds a threshold or via neurotransmitters released by synapses coming from other neurons. 
On the other side of the spectrum, an artificial neuron is simply a weighted summation of its inputs, followed by a non-linear function. This high-level abstraction is an extreme simplification of the underlying information processing mechanism. 
On the one hand, this simplification lets us easily design deep neural networks of millions of units with only a few code lines.
One the other hand, it raises the question of whether we lose some important properties and aspects of biological neurons.&lt;/p&gt;

&lt;p&gt;The second major difference between artificial and biological neural networks is their wiring architectures.
Biological neural networks appear chaotic at first glance and require extensive research to understand and characterize their wiring principles. 
Artificial neural networks have a well-defined layer-by-layer structure, which is often guided by computational reasons. For instance, cache efficient dense matrix multiplication algorithms make the use of fully-connected layers very convenient. Consequently, writing a fully-connected layer in Pytorch or TensorFlow requires fewer code lines than creating a sparsely connected layer.&lt;/p&gt;

&lt;p&gt;Given the two discrepancies between artificial and biological neural networks mentioned above, we ask the following question in our research:
What do we gain something, and what costs do we have to pay if we design more biologically inspired machine learning models?&lt;/p&gt;

&lt;p&gt;But there are already a million papers out there asking similar questions, what’s so special about your research?&lt;/p&gt;

&lt;p&gt;That’s correct. But different from other research out there, we don’t look at human brains for our inspirations.
We don’t even look at rats or mice brains for our comparisons.
Heck, we don’t even consider the brains of insects or fish for our study.
We look at the arguably simplest animal with a functioning nervous system out there: The &lt;em&gt;Caenorhabditis elegans&lt;/em&gt; worm.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/wormnet/c_elegans.jpg&quot; alt=&quot;award&quot; title=&quot;*C. elegans* adult (CC BY-SA 3.0)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From a modeling viewpoint, the &lt;em&gt;C. elegans&lt;/em&gt; organism has two key advantages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;C. elegans’ nervous system consists of only 302 neurons and around 9000 synapses, and its wiring is well-studied &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
  &lt;li&gt;The neurons of &lt;em&gt;C. elegans’&lt;/em&gt; nervous system don’t express any spiking patterns, which makes modeling them much simpler.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In our research, i.e., the wormnet project, we try to build machine learning models motivated by the &lt;em&gt;C. elegans&lt;/em&gt; nervous system. 
By doing so, we have to pay a cost, as we constrain ourselves to such models in contrast to standard artificial neural networks, whose modeling space is purely constraint by memory and compute limitations.
However, there are potentially some advantages and benefits we gain.
Our objective is to better understand what’s necessary for effective neural information processing to emerge.&lt;/p&gt;

&lt;h2 id=&quot;what-to-expect&quot;&gt;What to expect&lt;/h2&gt;

&lt;p&gt;In this blog series, we take a quick journey through four years of research, which started in 2016, up to our recent paper XXX. 
Essentially, we talk about the requirements and difficulties of each step of the following process:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/wormnet/ode_to_rnn.png&quot; alt=&quot;award&quot; title=&quot;Modelling process in a nutshell&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After that, we will discuss our observed advantages and downsides of using such a unique machine learning model.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://www.wormatlas.org/&quot;&gt;wormatlas.org&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="NCP" /><category term="wormnet" /><summary type="html">This is the first part in a series explaining our recent paper titled XXX.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/wormnet/tw.png" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/wormnet/tw.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">An unusual ODE-solver</title><link href="https://mlech26l.github.io/pages/2020/09/14/ode_solver.html" rel="alternate" type="text/html" title="An unusual ODE-solver" /><published>2020-09-14T00:00:00-05:00</published><updated>2020-09-14T00:00:00-05:00</updated><id>https://mlech26l.github.io/pages/2020/09/14/ode_solver</id><content type="html" xml:base="https://mlech26l.github.io/pages/2020/09/14/ode_solver.html">&lt;p&gt;This is the third part in a series explaining our recent paper titled XXX.
Here, we will derive an ODE-solver specifically created to deal with the numerical issues of our LTC neural network model.&lt;/p&gt;

&lt;h2 id=&quot;stiff-ordinary-differential-equations&quot;&gt;Stiff ordinary differential equations&lt;/h2&gt;

&lt;p&gt;In the previous part, we have defined an ODE-based neuron model, together with a non-linear synapse model.
One might say that this is already enough to build a recurrent neural network (RNN). People familiar with David Duvenaud’s research group’s work &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; might argue that we could simply put the ODE system into an off-the-shelf ODE-solver to obtain a solution at the required timesteps. 
Packages like torchdiffeq &lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; provide a set of powerful ODE-solvers like the Kunge-Kutta &lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; or the more sophisticated Dormand-Prince method &lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, which is even the default in Matlab &lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;.
However, there is one issue with the differential equations: They realize a phenomenon known as stiff equations &lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;.
For instance, if we simulate the unremarkable and linear ODE&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence=&quot;true&quot;&gt;(&lt;/mo&gt;&lt;mtable rowspacing=&quot;0.15999999999999992em&quot; columnspacing=&quot;1em&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;20.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;21.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mo fence=&quot;true&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\frac{d x}{d t} = \begin{pmatrix} 0 &amp;amp; 1\\ -20.5 &amp;amp; -21.5 \end{pmatrix} x&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.05744em;vertical-align:-0.686em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.37144em;&quot;&gt;&lt;span style=&quot;top:-2.314em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.677em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.686em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.40003em;vertical-align:-0.95003em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;minner&quot;&gt;&lt;span class=&quot;mopen delimcenter&quot; style=&quot;top:0em;&quot;&gt;&lt;span class=&quot;delimsizing size3&quot;&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mtable&quot;&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.45em;&quot;&gt;&lt;span style=&quot;top:-3.61em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-2.4099999999999997em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.9500000000000004em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;arraycolsep&quot; style=&quot;width:0.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;arraycolsep&quot; style=&quot;width:0.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.45em;&quot;&gt;&lt;span style=&quot;top:-3.61em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-2.4099999999999997em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.9500000000000004em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose delimcenter&quot; style=&quot;top:0em;&quot;&gt;&lt;span class=&quot;delimsizing size3&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;with a simple fixed-step solver, we might get something like&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/wormnet/diffeq/seq/explicit.gif&quot; alt=&quot;award&quot; title=&quot;The explicit Euler method applied to the linear ODE above&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Such a stiffness usually occurs when there are two antagonistic forces applied to a single variable. One force tries to increase the variable, while the other one wants to decrease it. In the analytical solution, both forces converge to a stable equilibrium. However, in a discrete-time numerical approximation, the two forces push the variable above and below the equilibrium. If the magnitude of this “pushing around” increases, the resulting numerical simulation becomes unstable, as we observed above.&lt;/p&gt;

&lt;p&gt;Dynamic stepsize solvers, like the Dormand-Prince method, deal with this issue by making the simulation grid finer if such divergence is detected. However, this solution comes at a very high computational cost, which we want to avoid.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Implicit ODE-solving methods&lt;/strong&gt; provide a more elegant solution.
Standard explicit methods like the explicit Euler, Runge-Kutta, and the Dormand-Prince approach all simulate a differential equation like&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mtext&gt;solver_magic&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t+\Delta) = x(t) + \Delta \cdot \text{solver\_magic}(x(t))&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;⋅&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.06em;vertical-align:-0.31em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord&quot;&gt;solver_magic&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;In the simplest case, i.e., the explicit Euler, &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mtext&gt;solver_magic&lt;/mtext&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\text{solver\_magic}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.00444em;vertical-align:-0.31em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord&quot;&gt;solver_magic&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is simply the right-hand-size of the given ODE &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\frac{d x}{d t} = f(x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.2251079999999999em;vertical-align:-0.345em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.8801079999999999em;&quot;&gt;&lt;span style=&quot;top:-2.6550000000000002em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.394em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.345em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; evaluated at &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x=x(t)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;:&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t+\Delta) = x(t) + \Delta \cdot f(x(t))&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;⋅&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;The idea of implicit methods is define the numerical solution in an implcit equation,&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mtext&gt;solver_magic&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t+\Delta) = x(t) + \Delta \cdot \text{solver\_magic}(x(t+t))&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;⋅&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.06em;vertical-align:-0.31em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord text&quot;&gt;&lt;span class=&quot;mord&quot;&gt;solver_magic&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;The simplest case is the implicit Euler, which is defined as&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t+\Delta) = x(t) + \Delta \cdot f(x(t+\Delta))&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;⋅&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;If our ODE is linear, like the one illustrated above, we can analytically solve this equation and get&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence=&quot;true&quot;&gt;(&lt;/mo&gt;&lt;mtable rowspacing=&quot;0.15999999999999992em&quot; columnspacing=&quot;1em&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mo fence=&quot;true&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence=&quot;true&quot;&gt;(&lt;/mo&gt;&lt;mtable rowspacing=&quot;0.15999999999999992em&quot; columnspacing=&quot;1em&quot;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;20.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;false&quot;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;21.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;mo fence=&quot;true&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t+\Delta) = (\begin{pmatrix}1 &amp;amp; 0 \\0 &amp;amp; 1 \end{pmatrix} - \Delta\cdot \begin{pmatrix} 0 &amp;amp; 1\\ -20.5 &amp;amp; -21.5 \end{pmatrix})^{-1} x(t)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.40003em;vertical-align:-0.95003em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;minner&quot;&gt;&lt;span class=&quot;mopen delimcenter&quot; style=&quot;top:0em;&quot;&gt;&lt;span class=&quot;delimsizing size3&quot;&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mtable&quot;&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.45em;&quot;&gt;&lt;span style=&quot;top:-3.61em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-2.4099999999999997em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.9500000000000004em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;arraycolsep&quot; style=&quot;width:0.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;arraycolsep&quot; style=&quot;width:0.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.45em;&quot;&gt;&lt;span style=&quot;top:-3.61em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-2.4099999999999997em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.9500000000000004em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose delimcenter&quot; style=&quot;top:0em;&quot;&gt;&lt;span class=&quot;delimsizing size3&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;⋅&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.40003em;vertical-align:-0.95003em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;minner&quot;&gt;&lt;span class=&quot;mopen delimcenter&quot; style=&quot;top:0em;&quot;&gt;&lt;span class=&quot;delimsizing size3&quot;&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mtable&quot;&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.45em;&quot;&gt;&lt;span style=&quot;top:-3.61em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-2.4099999999999997em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.9500000000000004em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;arraycolsep&quot; style=&quot;width:0.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;arraycolsep&quot; style=&quot;width:0.5em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;col-align-c&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.45em;&quot;&gt;&lt;span style=&quot;top:-3.61em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-2.4099999999999997em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.9500000000000004em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose delimcenter&quot; style=&quot;top:0em;&quot;&gt;&lt;span class=&quot;delimsizing size3&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.864108em;&quot;&gt;&lt;span style=&quot;top:-3.113em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;which behaves smoothly and stable when run with the same stepsize as the figure above.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/wormnet/diffeq/euler_implicit.png&quot; alt=&quot;award&quot; title=&quot;Comparision of the explicit and implicit Euler method&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There is one catch though: implicit methods require solving a possible non-linear equation. We have two options for solving this equation: Analytically or numerically.
Solving the equation analytically as we have done in the implicit Euler method for the linear ODE above is not possible for our model due to the non-linear transcendental sigmoid function.
Solving the equation numerically is also not a legitimate option, as we would have to solve it every timestep, resulting in a high computational cost.&lt;/p&gt;

&lt;h2 id=&quot;a-hybrid-solution&quot;&gt;A hybrid solution&lt;/h2&gt;

&lt;p&gt;Our solution to this dilemma is a hybrid implicit/explicit ODE-solver. In our ODE model, the stiff parts, i.e., the terms that make the variables over- and undershoot the equilibrium, occur only linearly in the equation. 
Consequently, we can apply the explicit Euler method for computing the non-linear synapse activations and use the super-stable implicit Euler method for remaining linear ODE.
Mathematically, we discretize the ODE&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\frac{d x}{d t} = f(x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.05744em;vertical-align:-0.686em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.37144em;&quot;&gt;&lt;span style=&quot;top:-2.314em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.677em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.686em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;by the approach&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;↦&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t+\Delta) = x(t) + \Delta \cdot f(x \mapsto x(t)/x(t+\Delta))&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;⋅&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;↦&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;where we substitute &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; by &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; in the non-linear and &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; by &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Δ&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x(t+\Delta)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;Δ&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; in the linear occruances of &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; in &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;f&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8888799999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.10764em;&quot;&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.
After an extensive amount of re-writing, we can solve the ODE for (x+\Delta):&lt;/p&gt;

&lt;p&gt;From the equation of our hybrid solver, we can infer one important stability property. If we want to guarantee that we never divide by zero, we have to make sure that Gleak, Gsyn is non-negative, and Cm positive. This will be important later when we train these parameters.&lt;/p&gt;

&lt;p&gt;Now that we have overcome the stability issue, we need to talk about precision. Just because we have some stable discretization does not imply we accurately approximate the underlying ODE. Especially, Euler methods are known not to be the most precise solver choices.
Our approach to boost precision is to stack multiple ODE-solver steps into a single RNN computation step.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/wormnet/stacked_rnn.png&quot; alt=&quot;award&quot; title=&quot;We sequentially stack ODE-solver step into a single RNN-step to increase numerical precision&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This does not guarantee that we always approximate the system in all conditions with perfect precision, but that’s a tradeoff we can live with.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We showed how to obtain a stable and decently accurate discretization of our neural network model. In the next part, we will put this solution into a deep learning framework and learn its parameters from training data.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Rubanova et al. NeurIPS 2019. &lt;a href=&quot;https://papers.nips.cc/paper/8773-latent-ordinary-differential-equations-for-irregularly-sampled-time-series.pdf&quot;&gt;Latent ordinary differential equations for irregularly-sampled time series&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://github.com/rtqichen/torchdiffeq&quot;&gt;torchdiffeq&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://mathworld.wolfram.com/Runge-KuttaMethod.html&quot;&gt;Wolfram Mathworld - Runge-Kutta methods&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Dormand and Prince 1980, &lt;em&gt;A family of embedded Runge-Kutta formulae&lt;/em&gt;, J. Comp. Appl. Math., Vol. 6 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://www.mathworks.com/help/matlab/ref/ode45.html&quot;&gt;Matlab’s ode45&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://www.mathworks.com/company/newsletters/articles/stiff-differential-equations.html&quot;&gt;mathworks.com - Stiff Differential Equations&lt;/a&gt; &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="NCP" /><category term="wormnet" /><summary type="html">This is the third part in a series explaining our recent paper titled XXX. Here, we will derive an ODE-solver specifically created to deal with the numerical issues of our LTC neural network model.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/wormnet/tw.png" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/wormnet/tw.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">An old neuron model revisted</title><link href="https://mlech26l.github.io/pages/2020/09/14/the_model.html" rel="alternate" type="text/html" title="An old neuron model revisted" /><published>2020-09-14T00:00:00-05:00</published><updated>2020-09-14T00:00:00-05:00</updated><id>https://mlech26l.github.io/pages/2020/09/14/the_model</id><content type="html" xml:base="https://mlech26l.github.io/pages/2020/09/14/the_model.html">&lt;p&gt;This is the second part in a series explaining our recent paper titled XXX.&lt;/p&gt;

&lt;h2 id=&quot;neurons-are-cells&quot;&gt;Neurons are cells&lt;/h2&gt;

&lt;p&gt;As briefly discussed in the first part, the neuron model used in machine learning is quite a high-level abstraction of the complex cells neuroscience deals with. 
We have also talked about how the activation value of a neuron is actually an electrical potential caused by different concentrations of charged ions inside and outside the cell. 
Going one step further, there may be different ion concentrations at different locations inside the cell, resulting in the neuron not having a single activation value but a location-dependent potential.
We won’t go this far of construction such a compartmental model, but assume a neuron has a single electrical potential.
We start by modeling the neuron’s membrane that separates the ions inside and outside the cell as a capacitor.&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;C \frac{d v}{d t} = i(t)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.05744em;vertical-align:-0.686em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07153em;&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.37144em;&quot;&gt;&lt;span style=&quot;top:-2.314em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.677em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.686em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;The voltage the capacitor is charged to represent the activation of the neuron. The idea of modeling a neuron’s membrane as a capacitor dates back to 1907 &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; and is used is many influencial neuron models &lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.
Next, we assume the neuron has a resting potential: the potential it wants to attain when no external stimulus is applied to the neuron.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/wormnet/circuit/rc.png&quot; alt=&quot;award&quot; title=&quot;A neuron is modelled as a capacitor&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A network of such standalone RC-circuits is quite boring, so we need a synapse model to let the neurons communicate with each other.
Physical synapses trigger an increase of certain ions in the post-synaptic neuron through neurotransmitters released by the pre-synaptic neuron. As a result, the post-synaptic neuron’s potential increases or decreases, depending on the ions’ flow direction and polarity. The release of neurotransmitters itself is triggered by pre-synaptic neuron’s potential exceeding a certain threshold.
We model this process by adding the following electrical circuit to the post-synaptic neuron,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/wormnet/circuit/syn.png&quot; alt=&quot;award&quot; title=&quot;A neuron connected by two incomming synapses 1 and 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;E_{rev,}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.969438em;vertical-align:-0.286108em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15139200000000003em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;mpunct mtight&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.286108em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; determines the reverse-potential, i.e., the potential toward which the synapses pushes the post-synaptic neuron’s potential. In the case of an excitatory synapse, this value is larger than the resting potential (activating the neuron). In the case of an inhibitory synapse, &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;E_{rev,k}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.969438em;vertical-align:-0.286108em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.05764em;&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.3361079999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;mpunct mtight&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.286108em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;  is lower than the resting potential (deactivating the neuron).&lt;/p&gt;

&lt;p&gt;The interesting &lt;strong&gt;non-linear&lt;/strong&gt; dynamics of the synapse happens inside the varistor &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;g_{k}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.625em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.33610799999999996em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; . The conductance of it is governed by the equation&lt;/p&gt;

&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;exp&lt;/mi&gt;&lt;mo&gt;⁡&lt;/mo&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;g_k = \frac{G_k}{1+\exp{(-\sigma  v_{pre,k} + \mu_{k})}}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.625em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.33610799999999996em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:2.332438em;vertical-align:-0.972108em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen nulldelimiter&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mfrac&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:1.36033em;&quot;&gt;&lt;span style=&quot;top:-2.314em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mop&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;σ&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.3361079999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mpunct mtight&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.286108em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;μ&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.33610799999999996em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.23em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;frac-line&quot; style=&quot;border-bottom-width:0.04em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;top:-3.677em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:3em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.33610799999999996em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.972108em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose nulldelimiter&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;

&lt;p&gt;, where &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;v_{pre,k}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.716668em;vertical-align:-0.286108em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.3361079999999999em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.02778em;&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mpunct mtight&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.286108em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the pre-synaptic neuron’s potential, &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;σ&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo separator=&quot;true&quot;&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;μ&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;G_k,\sigma_k,\mu_k&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8777699999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.33610799999999996em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03588em;&quot;&gt;σ&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.33610799999999996em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.16666666666666666em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;μ&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.33610799999999996em;&quot;&gt;&lt;span style=&quot;top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.15em;&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; weights of the synapse.&lt;/p&gt;

&lt;p&gt;Now that we have a neuron model and a synapse model to let the neurons talk to each other, we still miss a critical part of a neural network: the inputs and outputs. In C. elegans’ nervous system, physical inputs are introduced into the network through sensory neurons, i.e., neurons whose potential is influenced by external stimulus. Analogously, dedicated motor neurons take care of producing a physical response from the information processing inside C. elegans’ nervous system.&lt;/p&gt;

&lt;p&gt;In our computational model, we will treat motor neurons as normal neurons and define the network’s output as the potential of these motor neurons.
Moreover, we define the input variables’ values as the neuron potential of a separate set of sensory neurons. Thus, the potential of these sensory neurons cannot be affected by synapses, as it is determined solely by the values of the inputs. Consequently, sensory neurons can only have outgoing synapses but no incoming links.&lt;/p&gt;

&lt;p&gt;As the input and output variable might be differently scaled than the neuron values inside the network, we re-scale the input and output signals by element-wise affine transformations.&lt;/p&gt;

&lt;p&gt;Finally, we can write down the full model. Let’s say X are the inputs of the network and Y are the outputs of the network.&lt;/p&gt;

&lt;h2 id=&quot;is-this-really-used-in-neuroscience&quot;&gt;Is this really used in neuroscience?&lt;/h2&gt;
&lt;p&gt;The model introduce above does not originate from our imagination, but is actually taken from the book &lt;em&gt;Methods in Neuronal Modeling - From Ions to Networks&lt;/em&gt; &lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; by Christof Koch and Idan Segev and has been used in neuroscience research&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;]. 
There is one difference though between our model and the one defined in the neuroscience book. The model described by Koch and Segev models each synapse also via a differential equation, i.e., giving every synapse a possibly different temporal behavior. 
Our modification replaces the synapse ODEs by their steady-state solution for &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;→&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∞&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;t \rightarrow \infty&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.61508em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;→&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;∞&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. This simplification significantly reduces the memory requirement to store the RNN-state from squared to linear, while losing a bit of expressive power.
We called the resulting model the Liquid time constant (LTC) model. Why we named it that way and mathematical properties about it can be found in our arXiv preprint&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Abbott 1999. &lt;a href=&quot;https://www.sciencedirect.com/science/article/abs/pii/S0361923099001616&quot;&gt;Lapicque’s introduction of the integrate-and-fire model neuron (1907)&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://neuronaldynamics.epfl.ch/online/Ch2.S2.html&quot;&gt;Hodgkin-Huxley Model&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Koch and Segev &lt;a href=&quot;https://mitpress.mit.edu/books/methods-neuronal-modeling-second-edition&quot;&gt;&lt;em&gt;Methods in Neuronal Modeling - From Ions to Networks&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Wicks et al 1996. &lt;a href=&quot;https://www.jneurosci.org/content/jneuro/16/12/4017.full.pdf&quot;&gt;A Dynamic Network Simulation of the Nematode Tap Withdrawal Circuit: Predictions Concerning Synaptic Function Using Behavioral Criteria&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.04439&quot;&gt;Liquid Time-constant Networks&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="NCP" /><category term="wormnet" /><summary type="html">This is the second part in a series explaining our recent paper titled XXX.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/wormnet/tw.png" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/wormnet/tw.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">We won the 7th F1/TENTH Autonomous Grand Prix</title><link href="https://mlech26l.github.io/pages/2020/07/20/f1tenth.html" rel="alternate" type="text/html" title="We won the 7th F1/TENTH Autonomous Grand Prix" /><published>2020-07-20T00:00:00-05:00</published><updated>2020-07-20T00:00:00-05:00</updated><id>https://mlech26l.github.io/pages/2020/07/20/f1tenth</id><content type="html" xml:base="https://mlech26l.github.io/pages/2020/07/20/f1tenth.html">&lt;p&gt;Our team won first place in the &lt;a href=&quot;https://ifac2020.f1tenth.org/&quot;&gt;7th F1/TENTH Autonomous Grand Prix at the World Congress of the International Federation of Automatic Control (IFAC 2020)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/f1tenth/official.png&quot; alt=&quot;award&quot; title=&quot;Winning certificate&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-f1tenth-grand-prix&quot;&gt;The F1/TENTH Grand Prix&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://f1tenth.org/&quot;&gt;F1/TENTH&lt;/a&gt; is a project about designing, building, and racing with autonomous cars at the scale of 1:10 of formula-1 cars (thus the name F1/TENTH). Initially founded by researchers from the University of Pennsylvania, F1/TENTH has attracted an international community and is regularly holding racing competitions. &lt;br /&gt;
The latest of these competitions, the 7th F1/TENTH Autonomous Grand Prix, was indented to be held physically in Berlin. However, due to Covid-19, the race was carried out virtually in a simulation environment. 
I and students from TU Wien participated in this Grand Prix under the team name &lt;em&gt;“TUfast TUfurious”&lt;/em&gt;. Out of a total of 13 submitted teams, including teams from, South Korea, U.S., and Italy, our team won the competition.&lt;/p&gt;

&lt;h2 id=&quot;our-approach&quot;&gt;Our approach&lt;/h2&gt;

&lt;p&gt;Our agent implements a path following algorithm based on the race map, which the organizers released a week before the competition. We tested our agent with several pre-computed paths, including a very smooth one and one that drives the curves very aggressively. Eventually, we settled for a path, as shown below (right), that comprises of long straight parts where the agent can accelerate.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/f1tenth/comb.png&quot; alt=&quot;award&quot; title=&quot;Left: Smooth baseline trajectory, Right: Proposed faster path&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After we fixed our path following core, we developed a velocity controller module. Based on the car’s current position, our velocity controller looks ahead of the planned path and estimates how much steering the agent has to do in the next couple of seconds. If the agent is expected to steer a lot, the velocity controller will reduce the car’s speed. Vice versa, if the track ahead is a straight part, the velocity controller will accelerate the vehicle. How far the velocity module looks ahead and how much to brake and accelerate in which conditions, is optimized using reinforcement learning.
As for the learning part, we opt for a good-old random search algorithm.
On top of the path following algorithm and the velocity controller, we implemented two methods that gave us an edge during the race.
Our first improvement is a manual starting maneuver. Essentially, at the beginning of the race, we overwrite the velocity controller by accelerating with the maximum throttle. After a few seconds, we assign the control back to the learned velocity module.
Our second improvement is a collision avoidance procedure. Our assumption the collision avoidance was that the opponents behave either near-optimal. Thus a safe overtaking during the race is not possible. Consequently, if our agent foresees colliding into the other car, for instance, because the other car slows down before a corner, our collision avoidance procedure slows down our car as well.&lt;/p&gt;

&lt;p&gt;After we implemented all parts of our agent, we rigorously tested it.
For instance, in the animation, we compared our agent to an opponent who performs a near-optimal start but then slows down halfway through the track.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/f1tenth/testing.gif&quot; alt=&quot;award&quot; title=&quot;Our agent (blue) vs a tested opponent that starts near-optimal but later slows down&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Our agent correctly foresees a crash a the beginning and slows down. After letting the opponent pass, our agent catches up quickly with the other car, when our agent has to slow down again to avoid a crash.&lt;/p&gt;

&lt;h2 id=&quot;the-competition&quot;&gt;The competition&lt;/h2&gt;
&lt;p&gt;During the head-to-head races, our agent demonstrated that it performs remarkably well in a variety of scenarios.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/f1tenth/f110.png&quot; alt=&quot;award&quot; title=&quot;Tournament bracket&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For instance, in the first race, our agent quickly overtook the opponent independently of starting in the advantaged or disadvantaged starting position.
In the second race, our agent correctly avoided a crash with the fast-starting opponent. Nonetheless, our agent won due to a faster lap time.
In the final race, our agent won because the other team’s car crashed into our agent, demonstrating how vital a well-tested collision avoidance is.
All-in-all our agent was able to win because it performed excellently in a diverse set of conditions.&lt;/p&gt;

&lt;h2 id=&quot;acknowledgement&quot;&gt;Acknowledgement&lt;/h2&gt;

&lt;p&gt;I want to thank all of my team members, Thomas Pintaric, Bernhard Schögl, Axel Brunnbauer, Hannes Brantner, and Andreas Brandstätter, for contributing to our submission and making the first-place possible. I also want to thank Radu Grosu for organizing the autonomous racing car course at TU Wien.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/f1tenth/celebrate3.jpg&quot; alt=&quot;award&quot; title=&quot;Prof. Radu Grosu celebrating&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="F1/TENTH" /><category term="Autonomous racing" /><summary type="html">Our team won first place in the 7th F1/TENTH Autonomous Grand Prix at the World Congress of the International Federation of Automatic Control (IFAC 2020).</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/f1tenth/car.jpg" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/f1tenth/car.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The dangers of biases in AI</title><link href="https://mlech26l.github.io/pages/2020/06/30/biases.html" rel="alternate" type="text/html" title="The dangers of biases in AI" /><published>2020-06-30T00:00:00-05:00</published><updated>2020-06-30T00:00:00-05:00</updated><id>https://mlech26l.github.io/pages/2020/06/30/biases</id><content type="html" xml:base="https://mlech26l.github.io/pages/2020/06/30/biases.html">&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;At the &lt;a href=&quot;http://cvpr2020.thecvf.com/&quot;&gt;2020 Conference on Computer Vision and Pattern Recognition (CVPR)&lt;/a&gt; Duke University published a new method title &lt;a href=&quot;https://arxiv.org/pdf/2003.03808.pdf&quot;&gt;Photo Upsampling via Latent Space Exploration (PULSE)&lt;/a&gt; for upsampling low resolution photos.
In a nutshell, PULSE searches the latent space of a generative model to find a high-resolution image that downsamples to an image that looks similar to the low-resolution input image. 
In particular, the authors achieved fascinating looking results by using  &lt;a href=&quot;https://github.com/NVlabs/stylegan&quot;&gt;StyleGAN&lt;/a&gt; trained on the &lt;a href=&quot;https://github.com/NVlabs/ffhq-dataset&quot;&gt;FFHQ&lt;/a&gt; dataset of high-resolution images of human faces.&lt;/p&gt;

&lt;p&gt;Indeed, if we run PULSE with downsampled images generated by StyleGAN itself, we get remarkable detailed results:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/biases/synthetic.png&quot; alt=&quot;synthetic&quot; title=&quot;Synthetic images (generated by PULSE/StyleGAN)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Nonetheless, the method has sparked extensive discussions about biases in AI. 
It all started with a tweet showing how PULSE upscaled a low-res picture of Barack Obama to a tanned white person.&lt;/p&gt;

&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;und&quot; dir=&quot;ltr&quot;&gt;🤔🤔🤔 &lt;a href=&quot;https://t.co/LG2cimkCFm&quot;&gt;pic.twitter.com/LG2cimkCFm&lt;/a&gt;&lt;/p&gt;&amp;mdash; Chicken3gg (@Chicken3gg) &lt;a href=&quot;https://twitter.com/Chicken3gg/status/1274314622447820801?ref_src=twsrc%5Etfw&quot;&gt;June 20, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;The authors explicitly state that &lt;em&gt;the objective of PULSE is not to reconstruct the original image, as this is impossible due to the lack of information in the low-res image&lt;/em&gt;. 
Nonetheless, one would never expect the low-res image of Barack Obama to be upscaled to the picture shown above.&lt;/p&gt;

&lt;p&gt;The authors claim that biased training data of StyleGAN most likely causes the observed bias. The used FFHQ dataset primarily comprises of faces of white people. 
They hypothesize that, due to this training data imbalance, the explored parts of the latent space by PULSE correspond predominately to white people’s faces.&lt;/p&gt;

&lt;h2 id=&quot;the-dangers-of-biased-ai&quot;&gt;The dangers of biased AI&lt;/h2&gt;

&lt;p&gt;Despite this claimed lack of training data diversity, what’s fascinating and dangerous at the same time is how this bias manifests in the AI.
To examine this, let’s downsample the Dancing Pallbearers and see what images PULSE will generate.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/biases/out.png&quot; alt=&quot;synthetic&quot; title=&quot;Upscaled Dancing Pallbearers (generated by PULSE/StyleGAN)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While the synthetic low-res images share color and shape profile of the corresponding real picture, we notice a crucial property in each upsample image: It’s always a white person. 
Surprisingly, the AI comes up with subtle reasons for explaining the skin tone and head covering in the input image. 
The skin tone is not caused by dark skin color but because the person in the synthetic image stands in a shaded area.
The white stripes on the hats are explained by sun rays hitting on that part of the person’s face.
Moreover, the black area from the top hat in the first image is explained by the high volume of the person’s hair.&lt;/p&gt;

&lt;p&gt;We see that the AI finds &lt;em&gt;creative&lt;/em&gt; ways to explain the features observed in the test images that weren’t there during training. This is precisely where the danger of biased AI systems lie. 
The AI can find solutions that are valid on a mathematical level (L2-distance) but unacceptable on a &lt;a href=&quot;https://iclr.cc/virtual_2020/speaker_3.html&quot;&gt;societal level&lt;/a&gt;.
We can repeat the experiments, but each time PULSE comes up with the same explanations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/biases/all_seeds.png&quot; alt=&quot;synthetic&quot; title=&quot;Upscaled Dancing Pallbearers different random seeds (generated by PULSE/StyleGAN)&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;bias-beyond-mathematics&quot;&gt;Bias beyond mathematics&lt;/h2&gt;

&lt;p&gt;The authors of the original paper performed an additional experiment to evaluate the &lt;strong&gt;'’success rate’‘&lt;/strong&gt; of PULSE of various groups (Female/Male, Black, East Asian, Indian, etc. ).
Their definition of success only concerns if the method finds an image that downsamples to a similar-looking image as the low-resolution input with respect to a pixel-based distance metric or not.
The authors found a marginal but non-significant difference in ‘‘success rate’’ among the tested groups. 
Essentially, as I stated above, on a mathematical level, the authors were unable to characterize a significant bias in the system.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Bias in machine learning is a sensitive topic that cannot be reduced to mathematics and training data imbalance alone. It mandates examinations involving societal and domain-specific experts.&lt;/p&gt;</content><author><name></name></author><category term="Bias" /><category term="AI" /><summary type="html">Background</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/biases/thumb.jpg" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/biases/thumb.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">5 Myths about quantized neural networks</title><link href="https://mlech26l.github.io/pages/jupyter/quantization/2020/06/28/quantization.html" rel="alternate" type="text/html" title="5 Myths about quantized neural networks" /><published>2020-06-28T00:00:00-05:00</published><updated>2020-06-28T00:00:00-05:00</updated><id>https://mlech26l.github.io/pages/jupyter/quantization/2020/06/28/quantization</id><content type="html" xml:base="https://mlech26l.github.io/pages/jupyter/quantization/2020/06/28/quantization.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-28-quantization.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Background:-What-are-quantized-neural-networks?&quot;&gt;Background: What are quantized neural networks?&lt;a class=&quot;anchor-link&quot; href=&quot;#Background:-What-are-quantized-neural-networks?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;When we run numerical algorithms on our computer, we need to make sacrifices in terms of precision for the sake of runtime. 
For instance, the square root of 2 is an irrational number and has an infinite amount of decimal digits. 
Thus we need to decide how many digits we really need for our application.
Each extra digit of precision increases the memory and time requirements to store and compute a variable.&lt;/p&gt;
&lt;p&gt;For example, the IEEE-754 standard specifies four types of floating-point formats:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;np.sqrt(2):
float128: 1.4142135623730950488
float64:  1.4142135623730951
float32:  1.4142135
float16:  1.414
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;For machine learning applications, the &lt;code&gt;float32&lt;/code&gt; format has been the default choice, as it provides a decent performance while avoiding extreme numerical errors. 
However, in the past decade researcher have made the following two observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;During the training phase, certain types of layers can be run and trained with lower precision (e.g., &lt;code&gt;float16&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;After the training phase (=inference phase), neural networks can run with much lower precision levels without sacrificing much accuracy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Consequently, Nvidia's latest &lt;a href=&quot;https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf&quot;&gt;A100 GPU&lt;/a&gt; supports the following six numerical format:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Data type&lt;/th&gt;
      &lt;th&gt;Significand precision&lt;/th&gt;
      &lt;th&gt;Exponent&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;float64&lt;/td&gt;
      &lt;td&gt;52-bits&lt;/td&gt;
      &lt;td&gt;11-bits&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;float32&lt;/td&gt;
      &lt;td&gt;23-bits&lt;/td&gt;
      &lt;td&gt;8-bits&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;TensorFloat32&lt;/td&gt;
      &lt;td&gt;10-bits&lt;/td&gt;
      &lt;td&gt;8-bits&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;float16&lt;/td&gt;
      &lt;td&gt;10-bits&lt;/td&gt;
      &lt;td&gt;5-bits&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;bfloat16&lt;/td&gt;
      &lt;td&gt;7-bits&lt;/td&gt;
      &lt;td&gt;8-bits&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;int8&lt;/td&gt;
      &lt;td&gt;7-bits&lt;/td&gt;
      &lt;td&gt;0-bits&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;One item that stands out in this list is the last row: While all other formats are based on a floating-point representation, &lt;code&gt;int8&lt;/code&gt; is an integer type.&lt;/p&gt;
&lt;p&gt;This raises the question:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;How can we run a neural network with integer operations?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The answer is quantization.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Quantization translates a network that operates over floating-point variables into a network that uses fixed-point arithmetic&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Fixed-point_arithmetic&quot;&gt;Fixed-point arithmetic&lt;/a&gt; is a numerical format that can be implemented relatively efficiently used integer operations.For instance, we can use the first four bits of an &lt;code&gt;int8&lt;/code&gt; value to represent the digits before the comma, and the last four bits to represent fractional digits that come after the comma:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Decimal: 0.5       + 1.25      = 1.75
Binary:  0000.1000 + 0001.0100 = 0001.1100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A fixed-point addition can be implemented by simple integer addition and a fixed-point multiplication by an integer multiplication followed by a bit-wise shift operation.&lt;/p&gt;
&lt;p&gt;Obviously, the precision achieved with an 8-bit fixed-point format is not enough for training a neural network. However, most types of layers can be quantized for inferencing without suffering a significant loss in accuracy.
The quantization step itself rounds the &lt;code&gt;float32&lt;/code&gt; weight values to their nearest corresponding fixed-point value.&lt;/p&gt;
&lt;p&gt;The clear advantages of running a network using &lt;code&gt;int8&lt;/code&gt; is that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It requires less memory, which improves cache and memory bandwidth efficiency.&lt;/li&gt;
&lt;li&gt;Can run using more efficient integer operations&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In particular, a &lt;a href=&quot;https://arxiv.org/pdf/1704.04760.pdf&quot;&gt;2017 Google paper&lt;/a&gt; writes:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Eight-bit integer multiplies can be 6X less energy and 6X less area than IEEE 754 16-bit floating-point multiplies and the
advantage for integer addition is 13X in energy and 38X in area [Dal16].&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;- ''In-Datacenter Performance Analysis of a Tensor Processing Unit'' - Jouppi et al.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Despite this relatively simple concept, there are several misconceptions and myths regarding quantized neural networks:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Myth-#1:-Quantization-is-only-necessary-for-ultra-low-power-embedded-systems&quot;&gt;Myth #1: Quantization is only necessary for ultra-low-power embedded systems&lt;a class=&quot;anchor-link&quot; href=&quot;#Myth-#1:-Quantization-is-only-necessary-for-ultra-low-power-embedded-systems&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Far from it. Datacenter applications currently benefit the most from quantization. 
For instance, the first generation of &lt;a href=&quot;https://arxiv.org/pdf/1704.04760.pdf&quot;&gt;Google's Tensor Processing Units (TPUs)&lt;/a&gt; only supported quantized networks. Computation units for floating-point arithmetic were only added in the &lt;a href=&quot;https://www.tomshardware.com/news/tpu-v2-google-machine-learning,35370.html&quot;&gt;second generation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Likewise, Nvidia's &lt;a href=&quot;https://www.microway.com/knowledge-center-articles/in-depth-comparison-of-nvidia-tesla-volta-gpu-accelerators/&quot;&gt;V100&lt;/a&gt; and latest &lt;a href=&quot;https://www.anandtech.com/show/15801/nvidia-announces-ampere-architecture-and-a100-products&quot;&gt;A100&lt;/a&gt; can
perform four times as many &lt;code&gt;int8&lt;/code&gt; tensor operations compared to &lt;code&gt;float32&lt;/code&gt; operations per second (or twice as much &lt;code&gt;int8&lt;/code&gt; as &lt;code&gt;float16&lt;/code&gt; tensor operations per second).
This means that you can &lt;strong&gt;quadruple the throughput of your datacenter application&lt;/strong&gt; with quantization in a best-case scenario.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Myth-#2:-Quantization-makes-networks-smaller-but-not-faster&quot;&gt;Myth #2: Quantization makes networks smaller but not faster&lt;a class=&quot;anchor-link&quot; href=&quot;#Myth-#2:-Quantization-makes-networks-smaller-but-not-faster&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As already hinted in the myth above, modern AI accelerators such as GPU and TPU can run integer operations faster than floating-point operations.
Let's look at the compute performance of Nvidia's latest &lt;a href=&quot;https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf&quot;&gt;A100 GPU&lt;/a&gt;:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-57d3f3f031fc4a539098d324364e298e&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== &quot;altair-viz-57d3f3f031fc4a539098d324364e298e&quot;) {
      outputDiv = document.getElementById(&quot;altair-viz-57d3f3f031fc4a539098d324364e298e&quot;);
    }
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;layer&quot;: [{&quot;mark&quot;: &quot;bar&quot;, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Data type&quot;, &quot;legend&quot;: null, &quot;scale&quot;: {&quot;scheme&quot;: &quot;dark2&quot;}}, &quot;tooltip&quot;: [{&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Data type&quot;}, {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;TOPS&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Comment&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Significand precision&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Exponent&quot;}], &quot;x&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;axis&quot;: {&quot;labels&quot;: false, &quot;title&quot;: &quot;Data format&quot;}, &quot;field&quot;: &quot;Data type&quot;, &quot;sort&quot;: [&quot;float64&quot;, &quot;float32&quot;, &quot;TensorFloat32&quot;, &quot;float16&quot;, &quot;bfloat16&quot;, &quot;int8&quot;]}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;axis&quot;: {&quot;title&quot;: &quot;Tera op/s&quot;}, &quot;field&quot;: &quot;TOPS&quot;}}, &quot;height&quot;: 300, &quot;title&quot;: &quot;Nvidia A100 compute performance&quot;, &quot;width&quot;: 600}, {&quot;mark&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;align&quot;: &quot;center&quot;, &quot;baseline&quot;: &quot;middle&quot;, &quot;dy&quot;: -10, &quot;fontSize&quot;: 16}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Data type&quot;, &quot;legend&quot;: null, &quot;scale&quot;: {&quot;scheme&quot;: &quot;dark2&quot;}}, &quot;text&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Data type&quot;}, &quot;tooltip&quot;: [{&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Data type&quot;}, {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;TOPS&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Comment&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Significand precision&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Exponent&quot;}], &quot;x&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;axis&quot;: {&quot;labels&quot;: false, &quot;title&quot;: &quot;Data format&quot;}, &quot;field&quot;: &quot;Data type&quot;, &quot;sort&quot;: [&quot;float64&quot;, &quot;float32&quot;, &quot;TensorFloat32&quot;, &quot;float16&quot;, &quot;bfloat16&quot;, &quot;int8&quot;]}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;axis&quot;: {&quot;title&quot;: &quot;Tera op/s&quot;}, &quot;field&quot;: &quot;TOPS&quot;}}, &quot;height&quot;: 300, &quot;title&quot;: &quot;Nvidia A100 compute performance&quot;, &quot;width&quot;: 600}], &quot;data&quot;: {&quot;name&quot;: &quot;data-150720172dd484d891e26d6e7b27f0a1&quot;}, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.8.1.json&quot;, &quot;datasets&quot;: {&quot;data-150720172dd484d891e26d6e7b27f0a1&quot;: [{&quot;Data type&quot;: &quot;float64&quot;, &quot;TOPS&quot;: 9.7, &quot;Significand precision&quot;: &quot;52-bits&quot;, &quot;Exponent&quot;: &quot;11-bits&quot;, &quot;Comment&quot;: &quot;Double precision IEE-754 floating-point&quot;}, {&quot;Data type&quot;: &quot;float32&quot;, &quot;TOPS&quot;: 19.5, &quot;Significand precision&quot;: &quot;23-bits&quot;, &quot;Exponent&quot;: &quot;8-bits&quot;, &quot;Comment&quot;: &quot;Single precision IEE-754 floating-point&quot;}, {&quot;Data type&quot;: &quot;TensorFloat32&quot;, &quot;TOPS&quot;: 156.0, &quot;Significand precision&quot;: &quot;10-bits&quot;, &quot;Exponent&quot;: &quot;8-bits&quot;, &quot;Comment&quot;: &quot;32-bit floating-point format with reduced significand precision&quot;}, {&quot;Data type&quot;: &quot;float16&quot;, &quot;TOPS&quot;: 312.0, &quot;Significand precision&quot;: &quot;10-bits&quot;, &quot;Exponent&quot;: &quot;5-bits&quot;, &quot;Comment&quot;: &quot;Half precision IEE-754 floating-point&quot;}, {&quot;Data type&quot;: &quot;bfloat16&quot;, &quot;TOPS&quot;: 312.0, &quot;Significand precision&quot;: &quot;7-bits&quot;, &quot;Exponent&quot;: &quot;8-bits&quot;, &quot;Comment&quot;: &quot;16-bit brain-float format with larger range but reduced significand precision&quot;}, {&quot;Data type&quot;: &quot;int8&quot;, &quot;TOPS&quot;: 624.0, &quot;Significand precision&quot;: &quot;7-bits&quot;, &quot;Exponent&quot;: &quot;0-bits&quot;, &quot;Comment&quot;: &quot;8-bit integer format for fixed-point arithmetic&quot;}]}}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Essentially, quantization does not only make the network smaller, but makes them also &lt;strong&gt;runs faster&lt;/strong&gt;!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Myth-#3:-Any-layer-in-a-neural-network-can-be-quantized&quot;&gt;Myth #3: Any layer in a neural network can be quantized&lt;a class=&quot;anchor-link&quot; href=&quot;#Myth-#3:-Any-layer-in-a-neural-network-can-be-quantized&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Some types of layers do not tolerate quantization very well. For example, in &lt;a href=&quot;https://openreview.net/forum?id=HkxjYoCqKX&amp;amp;noteId=rygmk1EDT7&quot;&gt;a discussion of an ICLR paper by Max Welling's group&lt;/a&gt; we see that quantizing the first or the last layer of a network results in a considerable drop in accuracy. 
This gap does not entirely close even if we train the network using &lt;a href=&quot;https://arxiv.org/pdf/1712.05877.pdf&quot;&gt;quantization-aware training&lt;/a&gt; techniques.&lt;/p&gt;
&lt;p&gt;One trick often used to avoid this drop in accuracy is not to quantize the first and the last layer. 
As these two layers only take up a small fraction of the computations inside a network, running the first and the last layer with &lt;code&gt;float32&lt;/code&gt; does not hurt throughput much, but significantly benefits the accuracy of the network.&lt;/p&gt;
&lt;p&gt;However, one some end-devices, this approach is not an option. For instance, &lt;a href=&quot;https://cloud.google.com/edge-tpu&quot;&gt;Google's Edge TPU&lt;/a&gt; only supports &lt;code&gt;int8&lt;/code&gt;. Therefore, in such cases, every layer of the network must be quantized to 8-bit integers.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Myth-#4:-It's-easy-to-compare-different-quantization-approaches&quot;&gt;Myth #4: It's easy to compare different quantization approaches&lt;a class=&quot;anchor-link&quot; href=&quot;#Myth-#4:-It's-easy-to-compare-different-quantization-approaches&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Comparing two different quantization methods is not a trivial job. 
Connecting to the discussion above, let's imagine we have a network and quantize it with two different methods to obtain network A and network B.
While network A achieves a 90% accuracy by quantized all layers, network B achieves a 92% accuracy but leaves the first layer running with floating-point precision.&lt;/p&gt;
&lt;p&gt;Which method is better?&lt;/p&gt;
&lt;p&gt;The answer to this question depends on the context; which target device will the network run on?
If it's a device without a floating-point unit such as the Edge TPU or a microcontroller, then method A is clearly better. 
Contrarily, if we plan to run the network on a V100 or A100 GPU, then method B might be the better approach.&lt;/p&gt;
&lt;p&gt;Another technique that causes a lot of misconceptions found in &lt;a href=&quot;https://openreview.net/forum?id=HkxjYoCqKX&amp;amp;noteId=rygmk1EDT7&quot;&gt;the discussion of the ICLR paper by Max Welling's group&lt;/a&gt; are &lt;strong&gt;non-uniform quantization schemes&lt;/strong&gt;:
Fixed-point formats partition the representable value range using a uniform grid, e.g., there are the same amount of intermediate values between 1.5 and 2.5 as between 2.5 and 3.5. 
Looking at the typical weight distribution of neural networks, we notice that they follow a Gaussian-like bell curve distribution with smaller values occurring more frequently than large weight values.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;If our only objective is to represent the weight values as accurately as possible using only 8-bits per parameter, then a logarithmic grid provides a better choice than the uniform partitioning of fixed-point formats.
Although such non-uniform quantization approaches can remarkably compress the weights of the network, they destroy the critical advantage of quantization: The enabling of efficient integer arithmetic.&lt;/p&gt;
&lt;p&gt;In essence, comparing different quantization methods can be quite challenging as there are many tradeoffs to be considered.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Myth-#5:-A-8-bit-network-uses-only-8-bit-variables&quot;&gt;Myth #5: A 8-bit network uses only 8-bit variables&lt;a class=&quot;anchor-link&quot; href=&quot;#Myth-#5:-A-8-bit-network-uses-only-8-bit-variables&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In an 8-bit quantized neural network, all weights and activations are 8-bit integer variables.
However, when we run the network, we need 32-bits accumulation registers internally to represent intermediate results.&lt;/p&gt;
&lt;p&gt;Let's take a look at the C-like implementation of a typical ReLU neuron:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu_neuron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Essentially all variables, the weights, the inputs, and the accumulator, are represented by the 32-bit floating-point type.
For a neural network in a fixed-point format, we need a wider integer accumulation register to perform the multiplications and summation.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int8_t&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu_neuron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int8_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int8_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shift&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int32_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Multiplying two 8-bit integers requires a 16-bit register&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int16_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;product&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Sum over several 16-bit integers requires an even larger register (e.g. int32_t)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;product&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Fixed-point multiplication requires a shift&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shift&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Project neuron value back to valid int8_t range&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INT8_MAX&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Cast 32-bit accumulator back to 8-bit integer&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int8_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that the parameter &lt;code&gt;shift&lt;/code&gt; depends on the exact fixed-point format we employ, i.e., how many bits we use for storing the digits before and how many bits we use for storing the digits after the comma.&lt;/p&gt;
&lt;p&gt;Page 27 of &lt;a href=&quot;https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf&quot;&gt;Nvidia's A100 whitepaper&lt;/a&gt; specifies precisely which numerical format uses which numerical type for representing the &lt;strong&gt;input operands and the accumulation registers&lt;/strong&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Conclusion&quot;&gt;Conclusion&lt;a class=&quot;anchor-link&quot; href=&quot;#Conclusion&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Although the concept of neural network quantization is relatively simple, there are subtle details that can cause misconceptions. 
In this post, we have busted five common myths regarding quantized neural networks.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Mathias Lechner</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/die.jpg" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/die.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The Teraflops era</title><link href="https://mlech26l.github.io/pages/jupyter/2020/06/08/gpu.html" rel="alternate" type="text/html" title="The Teraflops era" /><published>2020-06-08T00:00:00-05:00</published><updated>2020-06-08T00:00:00-05:00</updated><id>https://mlech26l.github.io/pages/jupyter/2020/06/08/gpu</id><content type="html" xml:base="https://mlech26l.github.io/pages/jupyter/2020/06/08/gpu.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-08-gpu.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;OpenAI recently released a &lt;a href=&quot;https://openai.com/blog/ai-and-efficiency/&quot;&gt;blog post&lt;/a&gt;, showing that the advances in algorithmic efficiency for training neural nets outpaced the scaling of Moore's law. 
In particular, the amount of transistors in silicon chips &lt;a href=&quot;https://newsroom.intel.com/wp-content/uploads/sites/11/2018/05/moores-law-electronics.pdf&quot;&gt;doubles every two years&lt;/a&gt;, whereas the efficiency of training a neural net to a certain accuracy level currently doubles every 16 to 17 months. 
While this progress is impressive, I am arguing that Moore's law is one of the main drivers of machine learning research. Thus, the advances in neural nets training efficiency are built on the shoulders of Moore's law.
In essence, I am stating the following law:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The amount of machine learning experiments that can be done for a fixed budget &lt;strong&gt;doubles&lt;/strong&gt; every two years&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Moore's Law - Machine Learning Research Edition&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By &lt;em&gt;budget&lt;/em&gt; I am refering to time, money and compute resources. My definition of &lt;em&gt;machine learning experiments&lt;/em&gt; involves any experiment to test new network designs, layers, loss functions, and training methods (e.g., self-supervised pre-training).&lt;/p&gt;
&lt;h2 id=&quot;Machine-Learning-Research&quot;&gt;Machine Learning Research&lt;a class=&quot;anchor-link&quot; href=&quot;#Machine-Learning-Research&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;If we look at the methodology of machine learning research, we notice an iterative paradigm composed of the following steps.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We have an idea&lt;/li&gt;
&lt;li&gt;We test the idea&lt;/li&gt;
&lt;li&gt;Based on the results, we refine and improve the idea.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once this iterative process yields noteworthy results, the idea and corresponding test results get distilled into a research paper.&lt;/p&gt;
&lt;p&gt;Let's say we want to speed up our research. 
Common sense tells us that we can speed up any process by getting rid of its bottlenecks.
The most dominant bottleneck in the procedure above is obviously step number 2.&lt;/p&gt;
&lt;p&gt;We could run more machine learning experiments if we simply buy a larger quantity of faster compute units.
But what if our budget is limited? How can we speed up our research then?&lt;/p&gt;
&lt;p&gt;The answer is simply waiting.
Yes! Moore's law tells us that every 2 years, we get roughly twice the compute performance for the same budget.
For instance, here is a plot of how the 32-bit floating-point of Nvidia GPU performance increased in the past decade:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-592718543bd643aab4a24d9d3ae74b7e&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== &quot;altair-viz-592718543bd643aab4a24d9d3ae74b7e&quot;) {
      outputDiv = document.getElementById(&quot;altair-viz-592718543bd643aab4a24d9d3ae74b7e&quot;);
    }
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;layer&quot;: [{&quot;mark&quot;: {&quot;type&quot;: &quot;circle&quot;, &quot;size&quot;: 60}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Gen&quot;}, &quot;tooltip&quot;: [{&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Compute&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Node&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Gen&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Memory&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Tensor cores&quot;}], &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;Year&quot;, &quot;scale&quot;: {&quot;domain&quot;: [&quot;2010-01-01T00:00:00&quot;, &quot;2021-07-01T00:00:00&quot;]}}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;axis&quot;: {&quot;title&quot;: &quot;float32 Teraflop/s&quot;}, &quot;field&quot;: &quot;Compute&quot;}}, &quot;height&quot;: 400, &quot;width&quot;: 600}, {&quot;mark&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;align&quot;: &quot;left&quot;, &quot;baseline&quot;: &quot;middle&quot;, &quot;dx&quot;: 7}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Gen&quot;}, &quot;text&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;GPU&quot;}, &quot;tooltip&quot;: [{&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Compute&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Node&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Gen&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Memory&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Tensor cores&quot;}], &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;Year&quot;, &quot;scale&quot;: {&quot;domain&quot;: [&quot;2010-01-01T00:00:00&quot;, &quot;2021-07-01T00:00:00&quot;]}}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;axis&quot;: {&quot;title&quot;: &quot;float32 Teraflop/s&quot;}, &quot;field&quot;: &quot;Compute&quot;}}, &quot;height&quot;: 400, &quot;width&quot;: 600}], &quot;data&quot;: {&quot;name&quot;: &quot;data-08279906167b235556d6dbb6c29964f4&quot;}, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.8.1.json&quot;, &quot;datasets&quot;: {&quot;data-08279906167b235556d6dbb6c29964f4&quot;: [{&quot;GPU&quot;: &quot;GTX 580&quot;, &quot;Year&quot;: &quot;2010-11-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Fermi&quot;, &quot;Memory&quot;: &quot;1.5GB&quot;, &quot;Compute&quot;: 1.581, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;40nm&quot;}, {&quot;GPU&quot;: &quot;GTX 680&quot;, &quot;Year&quot;: &quot;2012-02-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Kepler&quot;, &quot;Memory&quot;: &quot;2GB&quot;, &quot;Compute&quot;: 3.25, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;K40&quot;, &quot;Year&quot;: &quot;2013-10-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Kepler&quot;, &quot;Memory&quot;: &quot;12GB&quot;, &quot;Compute&quot;: 5.046, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;Titan Black&quot;, &quot;Year&quot;: &quot;2014-02-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Kepler&quot;, &quot;Memory&quot;: &quot;6GB&quot;, &quot;Compute&quot;: 5.645, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;K80&quot;, &quot;Year&quot;: &quot;2014-11-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Kepler&quot;, &quot;Memory&quot;: &quot;2x12GB&quot;, &quot;Compute&quot;: 8.226, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;GTX 980 Ti&quot;, &quot;Year&quot;: &quot;2015-06-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Maxwell&quot;, &quot;Memory&quot;: &quot;6GB&quot;, &quot;Compute&quot;: 6.06, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;M40&quot;, &quot;Year&quot;: &quot;2015-11-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Maxwell&quot;, &quot;Memory&quot;: &quot;12GB&quot;, &quot;Compute&quot;: 6.844, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;GTX 1080&quot;, &quot;Year&quot;: &quot;2016-05-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Pascal&quot;, &quot;Memory&quot;: &quot;8GB&quot;, &quot;Compute&quot;: 8.873, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;16nm&quot;}, {&quot;GPU&quot;: &quot;P100&quot;, &quot;Year&quot;: &quot;2016-04-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Pascal&quot;, &quot;Memory&quot;: &quot;16GB&quot;, &quot;Compute&quot;: 10.61, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;16nm&quot;}, {&quot;GPU&quot;: &quot;GTX 1080Ti&quot;, &quot;Year&quot;: &quot;2017-03-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Pascal&quot;, &quot;Memory&quot;: &quot;11GB&quot;, &quot;Compute&quot;: 11.34, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;16nm&quot;}, {&quot;GPU&quot;: &quot;Titan V&quot;, &quot;Year&quot;: &quot;2017-12-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Volta&quot;, &quot;Memory&quot;: &quot;12GB&quot;, &quot;Compute&quot;: 14.9, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;12nm&quot;}, {&quot;GPU&quot;: &quot;V100&quot;, &quot;Year&quot;: &quot;2018-03-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Volta&quot;, &quot;Memory&quot;: &quot;16/32GB&quot;, &quot;Compute&quot;: 14.13, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;12nm&quot;}, {&quot;GPU&quot;: &quot;T4&quot;, &quot;Year&quot;: &quot;2018-09-13T00:00:00&quot;, &quot;Gen&quot;: &quot;Turing&quot;, &quot;Memory&quot;: &quot;16GB&quot;, &quot;Compute&quot;: 8.141, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;12nm&quot;}, {&quot;GPU&quot;: &quot;RTX 2080 Ti&quot;, &quot;Year&quot;: &quot;2018-11-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Turing&quot;, &quot;Memory&quot;: &quot;12GB&quot;, &quot;Compute&quot;: 13.45, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;12nm&quot;}, {&quot;GPU&quot;: &quot;Titan RTX&quot;, &quot;Year&quot;: &quot;2018-12-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Turing&quot;, &quot;Memory&quot;: &quot;24GB&quot;, &quot;Compute&quot;: 16.31, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;12nm&quot;}, {&quot;GPU&quot;: &quot;A100&quot;, &quot;Year&quot;: &quot;2020-05-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Ampere&quot;, &quot;Memory&quot;: &quot;40GB&quot;, &quot;Compute&quot;: 19.49, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;7nm&quot;}, {&quot;GPU&quot;: &quot;RTX 3090&quot;, &quot;Year&quot;: &quot;2020-09-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Ampere&quot;, &quot;Memory&quot;: &quot;24GB&quot;, &quot;Compute&quot;: 35.7, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;8nm&quot;}]}}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We see that in terms of float32 performance, the RTX 3090 released in September of 2020 offers around 23x the float32 throughput of the GTX 580 release 9 years and 10 months prior.&lt;/p&gt;
&lt;p&gt;Interestingly, this chart does not even include the improvements of &lt;a href=&quot;https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html&quot;&gt;mixed-precision methods&lt;/a&gt; and other tricks that achieve higher performance by sacrificing numerical precision. For instance, Nvidia's latest A100 can perform 156 Teraflop/s when using for machine learning dedicated TensorCores together with the slightly less precise &lt;a href=&quot;https://devblogs.nvidia.com/nvidia-ampere-architecture-in-depth/&quot;&gt;TensorFloat32&lt;/a&gt; numerical format.
If we compare the TensorFloat32 throughput of the A100 to the GTX 580 used by Alex Krizhevsky to train &lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&quot;&gt;AlexNet&lt;/a&gt;, we see a 100x scaling in compute performance in almost exactly ten years.&lt;/p&gt;
&lt;h2 id=&quot;But-what-about-larger-models-and-datasets?&quot;&gt;But what about larger models and datasets?&lt;a class=&quot;anchor-link&quot; href=&quot;#But-what-about-larger-models-and-datasets?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Of course, the statement about the doubling of the architecture tuning assumes that the datasets and extend of the networks does not change dramatically.
However, given that ImageNet is still the de-facto standard computer vision benchmark (special credit to Prof. Fei-Fei), and the fact that the top-performing networks in 2019/2020 (&lt;a href=&quot;https://arxiv.org/pdf/1905.11946.pdf&quot;&gt;EfficientNet&lt;/a&gt;) are smaller than their 2015/2016 counterparts (&lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;ResNet&lt;/a&gt;/&lt;a href=&quot;https://arxiv.org/pdf/1611.05431.pdf&quot;&gt;ResNeXt&lt;/a&gt;), this assumption seems to hold for now.&lt;/p&gt;
&lt;h2 id=&quot;Conclusion&quot;&gt;Conclusion&lt;a class=&quot;anchor-link&quot; href=&quot;#Conclusion&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Moore's law continues to make compute resources faster and cheaper. This increase in compute performance allows machine learning researchers to test a larger variety of new architecture and training methods. Therefore, I am expecting that research will continue to yield better neural archtectiures and training algorithms.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Mathias Lechner</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/gpu.jpg" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/gpu.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Distinguished Young Alumnus-Award</title><link href="https://mlech26l.github.io/pages/2018/01/20/epilog.html" rel="alternate" type="text/html" title="Distinguished Young Alumnus-Award" /><published>2018-01-20T00:00:00-06:00</published><updated>2018-01-20T00:00:00-06:00</updated><id>https://mlech26l.github.io/pages/2018/01/20/epilog</id><content type="html" xml:base="https://mlech26l.github.io/pages/2018/01/20/epilog.html">&lt;p&gt;I won the &lt;strong&gt;Distinguished Young Alumnus-Award&lt;/strong&gt; at the  &lt;a href=&quot;http://www.informatik.tuwien.ac.at/studium/studierende/epilog/2017ws&quot;&gt;Epilog&lt;/a&gt;
for my master thesis &lt;em&gt;Brain-inspired Neural Control&lt;/em&gt;. The award was given by the TU Wien faculty of Informatics and is endowed 1.500 EUR.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/distinguished.jpg&quot; alt=&quot;award&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;: 
The research paper of my master thesis has been published at the &lt;a href=&quot;https://ieeexplore.ieee.org/document/8793840&quot;&gt;2019 IEEE International Conference on Robotics and Automation (ICRA)&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="Award" /><category term="Epilog" /><category term="Distinguished Young Alumnus" /><summary type="html">I won the Distinguished Young Alumnus-Award at the Epilog for my master thesis Brain-inspired Neural Control. The award was given by the TU Wien faculty of Informatics and is endowed 1.500 EUR.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/distinguished_thumb.jpg" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/distinguished_thumb.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Tikz and Videos</title><link href="https://mlech26l.github.io/pages/2017/11/29/tikz_and_videos.html" rel="alternate" type="text/html" title="Tikz and Videos" /><published>2017-11-29T00:00:00-06:00</published><updated>2017-11-29T00:00:00-06:00</updated><id>https://mlech26l.github.io/pages/2017/11/29/tikz_and_videos</id><content type="html" xml:base="https://mlech26l.github.io/pages/2017/11/29/tikz_and_videos.html">&lt;p&gt;I am a really big fan of &lt;strong&gt;Vector graphics&lt;/strong&gt; and I exhaustively use &lt;a href=&quot;https://en.wikipedia.org/wiki/PGF/TikZ&quot;&gt;Tikz&lt;/a&gt; to draw such.
However, creating videos and cool animations with Tikz and Latex can be a bit messy.
So I have come up with a simple but effective hack to make generating videos with Latex easier.&lt;/p&gt;

&lt;p&gt;The key idea is to have two separated Latex files: One that is manually created and stays the same over the whole video, and one that is procedurally generated for each frame.
The manual one is created as you would do usually write your Latex image. However, all variables that are dynamic throughout the video (e.g. color, position, opacity, etc.) are defined by placeholders. And, guess what, the second Latex file (the procedurally generated one) then fills all the placeholder for each frame.&lt;/p&gt;

&lt;h1 id=&quot;drawing-a-frame&quot;&gt;Drawing a frame&lt;/h1&gt;
&lt;p&gt;My starting point is the manually designed Latex file, that is based on the following scheme:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-tex&quot; data-lang=&quot;tex&quot;&gt;&lt;span class=&quot;k&quot;&gt;\documentclass&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;[border=0cm,convert={outext=.png}]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;standalone&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;% Documentclass to directly create a PNG-files when invoking 'pdflatex'&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;\usepackage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;xcolor&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;\usepackage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;tikz&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;% Load dynamic variables&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;\input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;dynamic.tex&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;\begin{document}&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;\begin{tikzpicture}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;% My Latex code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;\node&lt;/span&gt; (start) at (0,0) [draw,fill=&lt;span class=&quot;k&quot;&gt;\mycolorsin&lt;/span&gt;] &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;A&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;;
&lt;span class=&quot;k&quot;&gt;\node&lt;/span&gt; (start) at (2,0) [draw,fill=&lt;span class=&quot;k&quot;&gt;\mycolorcos&lt;/span&gt;] &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;B&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;;

&lt;span class=&quot;nt&quot;&gt;\end{tikzpicture}&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;\end{document}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this case a two nodes are drawn, which colors (&lt;em&gt;\mycolor&lt;/em&gt;) should be animated.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/tikz/frame_000.png&quot; alt=&quot;Latex&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;filling-the-placeholders&quot;&gt;Filling the placeholders&lt;/h1&gt;

&lt;p&gt;In the next step I will create a simple &lt;em&gt;python&lt;/em&gt; script that generates the &lt;em&gt;dynamic.tex&lt;/em&gt; file and fills all the dynamic placeholder variables.
Moreover, the program invokes the Latex compiler to generate a PNG file out of the code and stores it in a directory.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;subprocess&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;shutil&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create directory for the frames
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sequence'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;makedirs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sequence'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example data for animation in range [0,100]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sin_seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;50.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;50.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cos_seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;50.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;50.0&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Loop over each frame
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create file with for dynamic variables
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dynamic_file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dynamic.tex'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dynamic_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;newcommand{&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;mycolorsin}{green!'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'!white}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dynamic_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;newcommand{&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;mycolorcos}{red!'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cos_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'!white}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dynamic_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create png with pdflatex
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pdflatex -shell-escape -interaction=nonstopmode example.tex'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Move frame into directory with frames
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;shutil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'example.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sequence/frame_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zfill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Finally, all I have to do is to animate the frames with &lt;a href=&quot;https://en.wikipedia.org/wiki/ImageMagick&quot;&gt;ImageMagick&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;convert &lt;span class=&quot;nt&quot;&gt;-loop&lt;/span&gt; 0 &lt;span class=&quot;nt&quot;&gt;-delay&lt;/span&gt; 2 sequence/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.png animation.gif&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/tikz/animation.gif&quot; alt=&quot;Latex&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;remarks&quot;&gt;Remarks&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Instead of using &lt;em&gt;\newcommand&lt;/em&gt; for each placeholder, it might be more convinient to use &lt;em&gt;tikzset&lt;/em&gt; or &lt;em&gt;tikzstyle&lt;/em&gt; (&lt;a href=&quot;https://tex.stackexchange.com/questions/52372/should-tikzset-or-tikzstyle-be-used-to-define-tikz-styles&quot;&gt;See here&lt;/a&gt;) to define the dynamic variables&lt;/li&gt;
  &lt;li&gt;If you want to create a video instead of an animation (mp4 instead of gif), you can easily do this with &lt;a href=&quot;https://en.wikipedia.org/wiki/FFmpeg&quot;&gt;ffmpeg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Technically the gif animation is not a vector graphics anymore. However by tuning the &lt;em&gt;pdf-to-png&lt;/em&gt; conversion density parameter, one can create an animation with an arbitrary high resolution.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="Tikz" /><category term="Latex" /><category term="Animation" /><category term="Video" /><summary type="html">I am a really big fan of Vector graphics and I exhaustively use Tikz to draw such. However, creating videos and cool animations with Tikz and Latex can be a bit messy. So I have come up with a simple but effective hack to make generating videos with Latex easier.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/tikz/map.jpg" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/tikz/map.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>