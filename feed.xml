<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://mlech26l.github.io/pages/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mlech26l.github.io/pages/" rel="alternate" type="text/html" /><updated>2020-06-07T15:12:08-05:00</updated><id>https://mlech26l.github.io/pages/feed.xml</id><title type="html">Home</title><subtitle>Personal research blog and webpage</subtitle><entry><title type="html">Mooreâ€™s Law - Machine Learning Research Edition</title><link href="https://mlech26l.github.io/pages/jupyter/2020/06/06/gpu.html" rel="alternate" type="text/html" title="Moore's Law - Machine Learning Research Edition" /><published>2020-06-06T00:00:00-05:00</published><updated>2020-06-06T00:00:00-05:00</updated><id>https://mlech26l.github.io/pages/jupyter/2020/06/06/gpu</id><content type="html" xml:base="https://mlech26l.github.io/pages/jupyter/2020/06/06/gpu.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-6-08-gpu.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;OpenAI recently released a &lt;a href=&quot;https://openai.com/blog/ai-and-efficiency/&quot;&gt;blog post&lt;/a&gt;, showing that the advances in algorithmic efficiency for training neural nets outpaced the scaling of Moore's law. 
In particular, the amount of transistors in silicon chips &lt;a href=&quot;https://newsroom.intel.com/wp-content/uploads/sites/11/2018/05/moores-law-electronics.pdf&quot;&gt;doubles every two years&lt;/a&gt;, whereas the efficiency of training a neural net to a certain accuracy level doubles every 16 to 17 months. 
While this progress is impressive, I am arguing that Moore's law is one of the main drivers of machine learning research. Thus, the advances in neural nets training efficiency are built on the shoulders of Moore's law.
In essence, I am stating the following law:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The amount of hyperparameter &amp;amp; architecture tuning that can be done for a fixed budget &lt;strong&gt;doubles&lt;/strong&gt; every two years&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Moore's Law - Machine Learning Research Edition&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By &lt;em&gt;budget&lt;/em&gt; I mean time, money and compute resources.&lt;/p&gt;
&lt;h2 id=&quot;Machine-Learning-Research&quot;&gt;Machine Learning Research&lt;a class=&quot;anchor-link&quot; href=&quot;#Machine-Learning-Research&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;If we look at the methodology of machine learning research, we notice an iterative paradigm composed of the following steps.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We have an idea&lt;/li&gt;
&lt;li&gt;We test the idea&lt;/li&gt;
&lt;li&gt;Based on the results, we refine and improve the idea.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once this iterative process yields noteworthy results, the idea and corresponding test results get distilled into a research paper.&lt;/p&gt;
&lt;p&gt;Let's say we want to speed up our research. 
Common sense tells us that we can speed up any process by getting rid of its bottlenecks.
The most dominant bottleneck in the procedure above is obviously step number 2.&lt;/p&gt;
&lt;p&gt;We could run more machine learning experiments if we simply buy a larger quantity of faster compute units.
But what if our budget is limited? How can we speed up our research then?&lt;/p&gt;
&lt;p&gt;The answer is simply waiting.
Yes! Moore's law tells us that every 2 years, we get roughly twice the compute performance for the same budget.
For instance, here is a plot of how the 32-bit floating-point of Nvidia GPU performance increased in the past decade:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-bff6319d7fc3476db42b13346ec17902&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== &quot;altair-viz-bff6319d7fc3476db42b13346ec17902&quot;) {
      outputDiv = document.getElementById(&quot;altair-viz-bff6319d7fc3476db42b13346ec17902&quot;);
    }
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;layer&quot;: [{&quot;mark&quot;: {&quot;type&quot;: &quot;circle&quot;, &quot;size&quot;: 60}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Gen&quot;}, &quot;tooltip&quot;: [{&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Compute&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Node&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Gen&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Memory&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Tensor cores&quot;}], &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;Year&quot;, &quot;scale&quot;: {&quot;domain&quot;: [&quot;2010-01-01T00:00:00&quot;, &quot;2021-01-01T00:00:00&quot;]}}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;axis&quot;: {&quot;title&quot;: &quot;float32 Teraflop/s&quot;}, &quot;field&quot;: &quot;Compute&quot;}}, &quot;height&quot;: 400, &quot;width&quot;: 600}, {&quot;mark&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;align&quot;: &quot;left&quot;, &quot;baseline&quot;: &quot;middle&quot;, &quot;dx&quot;: 7}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Gen&quot;}, &quot;text&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;GPU&quot;}, &quot;tooltip&quot;: [{&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Compute&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Node&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Gen&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Memory&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Tensor cores&quot;}], &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;Year&quot;, &quot;scale&quot;: {&quot;domain&quot;: [&quot;2010-01-01T00:00:00&quot;, &quot;2021-01-01T00:00:00&quot;]}}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;axis&quot;: {&quot;title&quot;: &quot;float32 Teraflop/s&quot;}, &quot;field&quot;: &quot;Compute&quot;}}, &quot;height&quot;: 400, &quot;width&quot;: 600}], &quot;data&quot;: {&quot;name&quot;: &quot;data-3b7fa562e835dc8443afef5290c12238&quot;}, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.8.1.json&quot;, &quot;datasets&quot;: {&quot;data-3b7fa562e835dc8443afef5290c12238&quot;: [{&quot;GPU&quot;: &quot;GTX 580&quot;, &quot;Year&quot;: &quot;2010-11-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Fermi&quot;, &quot;Memory&quot;: &quot;1.5GB&quot;, &quot;Compute&quot;: 1.581, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;40nm&quot;}, {&quot;GPU&quot;: &quot;GTX 680&quot;, &quot;Year&quot;: &quot;2012-02-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Kepler&quot;, &quot;Memory&quot;: &quot;2GB&quot;, &quot;Compute&quot;: 3.25, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;K40&quot;, &quot;Year&quot;: &quot;2013-10-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Kepler&quot;, &quot;Memory&quot;: &quot;12GB&quot;, &quot;Compute&quot;: 5.046, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;Titan Black&quot;, &quot;Year&quot;: &quot;2014-02-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Kepler&quot;, &quot;Memory&quot;: &quot;6GB&quot;, &quot;Compute&quot;: 5.645, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;K80&quot;, &quot;Year&quot;: &quot;2014-11-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Kepler&quot;, &quot;Memory&quot;: &quot;2x12GB&quot;, &quot;Compute&quot;: 8.226, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;GTX 980 Ti&quot;, &quot;Year&quot;: &quot;2015-06-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Maxwell&quot;, &quot;Memory&quot;: &quot;6GB&quot;, &quot;Compute&quot;: 6.06, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;M40&quot;, &quot;Year&quot;: &quot;2015-11-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Maxwell&quot;, &quot;Memory&quot;: &quot;12GB&quot;, &quot;Compute&quot;: 6.844, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;28nm&quot;}, {&quot;GPU&quot;: &quot;GTX 1080&quot;, &quot;Year&quot;: &quot;2016-05-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Pascal&quot;, &quot;Memory&quot;: &quot;8GB&quot;, &quot;Compute&quot;: 8.873, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;16nm&quot;}, {&quot;GPU&quot;: &quot;P100&quot;, &quot;Year&quot;: &quot;2016-04-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Pascal&quot;, &quot;Memory&quot;: &quot;16GB&quot;, &quot;Compute&quot;: 10.61, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;16nm&quot;}, {&quot;GPU&quot;: &quot;GTX 1080Ti&quot;, &quot;Year&quot;: &quot;2017-03-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Pascal&quot;, &quot;Memory&quot;: &quot;11GB&quot;, &quot;Compute&quot;: 11.34, &quot;Tensor cores&quot;: false, &quot;Node&quot;: &quot;16nm&quot;}, {&quot;GPU&quot;: &quot;Titan V&quot;, &quot;Year&quot;: &quot;2017-12-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Volta&quot;, &quot;Memory&quot;: &quot;12GB&quot;, &quot;Compute&quot;: 14.9, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;12nm&quot;}, {&quot;GPU&quot;: &quot;V100&quot;, &quot;Year&quot;: &quot;2018-03-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Volta&quot;, &quot;Memory&quot;: &quot;16/32GB&quot;, &quot;Compute&quot;: 14.13, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;12nm&quot;}, {&quot;GPU&quot;: &quot;RTX 2080 Ti&quot;, &quot;Year&quot;: &quot;2018-11-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Turing&quot;, &quot;Memory&quot;: &quot;12GB&quot;, &quot;Compute&quot;: 13.45, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;12nm&quot;}, {&quot;GPU&quot;: &quot;Titan RTX&quot;, &quot;Year&quot;: &quot;2018-12-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Turing&quot;, &quot;Memory&quot;: &quot;24GB&quot;, &quot;Compute&quot;: 16.31, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;12nm&quot;}, {&quot;GPU&quot;: &quot;A100&quot;, &quot;Year&quot;: &quot;2020-05-01T00:00:00&quot;, &quot;Gen&quot;: &quot;Ampere&quot;, &quot;Memory&quot;: &quot;40GB&quot;, &quot;Compute&quot;: 19.49, &quot;Tensor cores&quot;: true, &quot;Node&quot;: &quot;7nm&quot;}]}}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This chart does not even include the improvements of Mixed-precision methods and other tricks that achieve higher performance by sacrificing arithmetic precision. For instance, Nvidia's latest A100 can perform 156 Teraflop/s when using the slightly less precise &lt;a href=&quot;https://devblogs.nvidia.com/nvidia-ampere-architecture-in-depth/&quot;&gt;TensorFloat32&lt;/a&gt; format.
If we compare the TensorFloat32 throughput of the A100 to the GTX 580 used by Alex Krizhevsky to train &lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&quot;&gt;AlexNet&lt;/a&gt;, we see a 100x jump in compute performance in almost exactly ten years.&lt;/p&gt;
&lt;h2 id=&quot;But-what-about-larger-models-and-datasets?&quot;&gt;But what about larger models and datasets?&lt;a class=&quot;anchor-link&quot; href=&quot;#But-what-about-larger-models-and-datasets?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Of course, the statement about the doubling of the hyperparameter &amp;amp; architecture tuning assumes that the datasets and extend of the networks does not change dramatically.
However, given that ImageNet is still the de-facto standard computer vision benchmark (special credit to Prof. Fei-Fei), and the fact that the top-performing networks in 2020 (&lt;a href=&quot;https://arxiv.org/pdf/1905.11946.pdf&quot;&gt;EfficientNet&lt;/a&gt;) are smaller than their 2016 counterparts (ResNet/&lt;a href=&quot;https://arxiv.org/pdf/1611.05431.pdf&quot;&gt;ResNeXt&lt;/a&gt;), this assumptions holds.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Mathias Lechner</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mlech26l.github.io/pages/images/gpu.jpg" /><media:content medium="image" url="https://mlech26l.github.io/pages/images/gpu.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Distinguished Young Alumnus-Award</title><link href="https://mlech26l.github.io/pages/2018/01/20/epilog.html" rel="alternate" type="text/html" title="Distinguished Young Alumnus-Award" /><published>2018-01-20T00:00:00-06:00</published><updated>2018-01-20T00:00:00-06:00</updated><id>https://mlech26l.github.io/pages/2018/01/20/epilog</id><content type="html" xml:base="https://mlech26l.github.io/pages/2018/01/20/epilog.html">&lt;p&gt;I won the &lt;strong&gt;Distinguished Young Alumnus-Award&lt;/strong&gt; at the  &lt;a href=&quot;http://www.informatik.tuwien.ac.at/studium/studierende/epilog/2017ws&quot;&gt;Epilog&lt;/a&gt;
for my master thesis &lt;em&gt;Brain-inspired Neural Control&lt;/em&gt;. The award was given by the TU Wien faculty of Informatics and is endowed 1.500 EUR.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/distinguished.jpg&quot; alt=&quot;award&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;: 
The research paper of my master thesis has been published at the &lt;a href=&quot;https://ieeexplore.ieee.org/document/8793840&quot;&gt;2019 IEEE International Conference on Robotics and Automation (ICRA)&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="Award" /><category term="Epilog" /><category term="Distinguished Young Alumnus" /><summary type="html">I won the Distinguished Young Alumnus-Award at the Epilog for my master thesis Brain-inspired Neural Control. The award was given by the TU Wien faculty of Informatics and is endowed 1.500 EUR.</summary></entry><entry><title type="html">Tikz and Videos</title><link href="https://mlech26l.github.io/pages/2017/11/29/tikz_and_videos.html" rel="alternate" type="text/html" title="Tikz and Videos" /><published>2017-11-29T00:00:00-06:00</published><updated>2017-11-29T00:00:00-06:00</updated><id>https://mlech26l.github.io/pages/2017/11/29/tikz_and_videos</id><content type="html" xml:base="https://mlech26l.github.io/pages/2017/11/29/tikz_and_videos.html">&lt;p&gt;I am a really big fan of &lt;strong&gt;Vector graphics&lt;/strong&gt; and I exhaustively use &lt;a href=&quot;https://en.wikipedia.org/wiki/PGF/TikZ&quot;&gt;Tikz&lt;/a&gt; to draw such.
However, creating videos and cool animations with Tikz and Latex can be a bit messy.
So I have come up with a simple but effective hack to make generating videos with Latex easier.&lt;/p&gt;

&lt;p&gt;The key idea is to have two separated Latex files: One that is manually created and stays the same over the whole video, and one that is procedurally generated for each frame.
The manual one is created as you would do usually write your Latex image. However, all variables that are dynamic throughout the video (e.g. color, position, opacity, etc.) are defined by placeholders. And, guess what, the second Latex file (the procedurally generated one) then fills all the placeholder for each frame.&lt;/p&gt;

&lt;h1 id=&quot;drawing-a-frame&quot;&gt;Drawing a frame&lt;/h1&gt;
&lt;p&gt;My starting point is the manually designed Latex file, that is based on the following scheme:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-tex&quot; data-lang=&quot;tex&quot;&gt;&lt;span class=&quot;k&quot;&gt;\documentclass&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;[border=0cm,convert={outext=.png}]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;standalone&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;% Documentclass to directly create a PNG-files when invoking 'pdflatex'&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;\usepackage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;xcolor&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;\usepackage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;tikz&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;% Load dynamic variables&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;\input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;dynamic.tex&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;\begin{document}&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;\begin{tikzpicture}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;% My Latex code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;\node&lt;/span&gt; (start) at (0,0) [draw,fill=&lt;span class=&quot;k&quot;&gt;\mycolorsin&lt;/span&gt;] &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;A&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;;
&lt;span class=&quot;k&quot;&gt;\node&lt;/span&gt; (start) at (2,0) [draw,fill=&lt;span class=&quot;k&quot;&gt;\mycolorcos&lt;/span&gt;] &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;B&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;;

&lt;span class=&quot;nt&quot;&gt;\end{tikzpicture}&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;\end{document}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this case a two nodes are drawn, which colors (&lt;em&gt;\mycolor&lt;/em&gt;) should be animated.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/tikz/frame_000.png&quot; alt=&quot;Latex&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;filling-the-placeholders&quot;&gt;Filling the placeholders&lt;/h1&gt;

&lt;p&gt;In the next step I will create a simple &lt;em&gt;python&lt;/em&gt; script that generates the &lt;em&gt;dynamic.tex&lt;/em&gt; file and fills all the dynamic placeholder variables.
Moreover, the program invokes the Latex compiler to generate a PNG file out of the code and stores it in a directory.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;subprocess&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;shutil&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create directory for the frames
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sequence'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;makedirs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sequence'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example data for animation in range [0,100]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sin_seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;50.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;50.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cos_seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;50.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;50.0&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Loop over each frame
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create file with for dynamic variables
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dynamic_file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dynamic.tex'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dynamic_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;newcommand{&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;mycolorsin}{green!'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'!white}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dynamic_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;newcommand{&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;mycolorcos}{red!'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cos_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'!white}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dynamic_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create png with pdflatex
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pdflatex -shell-escape -interaction=nonstopmode example.tex'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Move frame into directory with frames
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;shutil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'example.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sequence/frame_'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zfill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Finally, all I have to do is to animate the frames with &lt;a href=&quot;https://en.wikipedia.org/wiki/ImageMagick&quot;&gt;ImageMagick&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;convert &lt;span class=&quot;nt&quot;&gt;-loop&lt;/span&gt; 0 &lt;span class=&quot;nt&quot;&gt;-delay&lt;/span&gt; 2 sequence/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.png animation.gif&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;/pages/images/tikz/animation.gif&quot; alt=&quot;Latex&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;remarks&quot;&gt;Remarks&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Instead of using &lt;em&gt;\newcommand&lt;/em&gt; for each placeholder, it might be more convinient to use &lt;em&gt;tikzset&lt;/em&gt; or &lt;em&gt;tikzstyle&lt;/em&gt; (&lt;a href=&quot;https://tex.stackexchange.com/questions/52372/should-tikzset-or-tikzstyle-be-used-to-define-tikz-styles&quot;&gt;See here&lt;/a&gt;) to define the dynamic variables&lt;/li&gt;
  &lt;li&gt;If you want to create a video instead of an animation (mp4 instead of gif), you can easily do this with &lt;a href=&quot;https://en.wikipedia.org/wiki/FFmpeg&quot;&gt;ffmpeg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Technically the gif animation is not a vector graphics anymore. However by tuning the &lt;em&gt;pdf-to-png&lt;/em&gt; conversion density parameter, one can create an animation with an arbitrary high resolution.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="Tikz" /><category term="Latex" /><category term="Animation" /><category term="Video" /><summary type="html">I am a really big fan of Vector graphics and I exhaustively use Tikz to draw such. However, creating videos and cool animations with Tikz and Latex can be a bit messy. So I have come up with a simple but effective hack to make generating videos with Latex easier.</summary></entry></feed>